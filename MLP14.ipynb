{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import setproctitle\n",
    "setproctitle.setproctitle('BeijingFlow@shaoerzhuo')\n",
    "from __future__ import print_function\n",
    "import os, tqdm, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.datasets import DFGDataset, collate_fn\n",
    "import utils.metrics as metrics\n",
    "\n",
    "class config:\n",
    "    cuda_num = 0\n",
    "    cityname = 'beijing'\n",
    "    io = 'inflow'\n",
    "    time_slice = 48\n",
    "    epoch_num = 10000\n",
    "    batch_size = 2**12\n",
    "    interval = 50\n",
    "print(config.__dict__)\n",
    "\n",
    "checkin_cate = 14\n",
    "poi_cate = 14\n",
    "\n",
    "dataset_config = {\n",
    "    'cityname' : config.cityname,\n",
    "    'dataset_path' : os.path.join('/data2/shaoerzhuo/DeepFlowGen/Dataset', config.cityname, 'dataset'),\n",
    "    'i/o' : config.io,\n",
    "    'poi_cate' : poi_cate\n",
    "}\n",
    "\n",
    "flow_max = {'shanghai':{'inflow':8179.6667, 'outflow':9417.3333}, 'beijing':{'inflow':1583.9167, 'outflow':1925.8333}}[config.cityname][config.io]\n",
    "\n",
    "train_dataset = DFGDataset(dataset_config, 'train')\n",
    "valid_dataset = DFGDataset(dataset_config, 'valid')\n",
    "test_dataset = DFGDataset(dataset_config, 'test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, num_workers=10, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, num_workers=10, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, num_workers=10, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.len_time_vec = 24\n",
    "        self.hidden_dims = 128\n",
    "        self.cuda_num = config.cuda_num\n",
    "        \n",
    "        self.time_embedding = nn.Embedding(48, self.len_time_vec)\n",
    "        self.dense1 = nn.Sequential(nn.Linear(poi_cate * 2 + self.len_time_vec, self.hidden_dims), nn.Sigmoid())\n",
    "        self.dense_block = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims), nn.Sigmoid(), \n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims), nn.Sigmoid(), \n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims), nn.Sigmoid(), \n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims), nn.Sigmoid(), \n",
    "        )\n",
    "        self.dense2 = nn.Sequential(nn.Linear(self.hidden_dims, 1), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        poi = batch['poi'].cuda(self.cuda_num)\n",
    "        t = batch['t'].cuda(self.cuda_num)\n",
    "        \n",
    "        time_vec = self.time_embedding(t)[:, 0]\n",
    "        out = torch.cat([time_vec, poi], dim=1)\n",
    "        out = self.dense1(out)\n",
    "        out = self.dense_block(out)\n",
    "        out = self.dense2(out)\n",
    "        \n",
    "        return {'total_crowd_flow' : out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLP().cuda(config.cuda_num)\n",
    "model.criterion = nn.MSELoss().cuda(config.cuda_num)\n",
    "lr = 1e-4\n",
    "\n",
    "valid_list = [np.inf]\n",
    "min_string = ''\n",
    "    \n",
    "for epoch in tqdm.tqdm(range(config.epoch_num), ncols=70, ascii=True):\n",
    "    if epoch % 500 == 0:\n",
    "        lr /= 2\n",
    "        model.optimizer = optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8)\n",
    "    for batch in train_loader:\n",
    "        model.optimizer.zero_grad()\n",
    "        return_dict = model(batch)\n",
    "        loss = model.criterion(return_dict['total_crowd_flow'], batch['flow'].cuda(config.cuda_num))\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "    if epoch % config.interval == config.interval-1:\n",
    "        pred_total = []\n",
    "        target_total = []\n",
    "        for batch in valid_loader:\n",
    "            pred_total.append(model(batch)['total_crowd_flow'].detach().cpu().numpy())\n",
    "            target_total.append(batch['flow'].numpy())\n",
    "        pred_total = np.concatenate(pred_total, axis=0)\n",
    "        target_total = np.concatenate(target_total, axis=0)\n",
    "        MAE = metrics.get_MAE(pred_total, target_total) * flow_max\n",
    "        RMSE = metrics.get_RMSE(pred_total, target_total) * flow_max\n",
    "        NRMSE = metrics.get_NRMSE(pred_total, target_total)\n",
    "        print('Epoch={0}\\tMAE=\\t{1:.4f}\\tRMSE=\\t{2:.4f}\\tNRMSE=\\t{3:.4f}'.format(epoch, MAE, RMSE, NRMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
